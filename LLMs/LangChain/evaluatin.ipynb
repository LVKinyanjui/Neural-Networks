{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we evaluate the performance of our application. Interestingly, we can use LLMs themselves to gauge how our RAG pipeline is performing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "import datetime\n",
    "\n",
    "from langchain.chains import RetrievalQA\n",
    "from langchain.chat_models import ChatGooglePalm\n",
    "from langchain.embeddings import GooglePalmEmbeddings\n",
    "from langchain.document_loaders import CSVLoader\n",
    "from langchain.indexes import VectorstoreIndexCreator\n",
    "from langchain.vectorstores.pinecone import Pinecone\n",
    "from langchain.evaluation.qa import QAGenerateChain, QAEvalChain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "palm_key = os.getenv('PALM_API_KEY')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = CSVLoader(\"data/sample.csv\")\n",
    "data = loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGooglePalm(google_api_key=palm_key, temperature=0.0)\n",
    "embeddings = GooglePalmEmbeddings(google_api_key=palm_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pinecone\n",
    "\n",
    "# initialize pinecone\n",
    "pinecone.init(\n",
    "    api_key=os.getenv(\"PINECONE_API_KEY_02\"),  # find at app.pinecone.io\n",
    "    environment=os.getenv(\"PINECONE_ENV\"),  # next to api key in console\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "docsearch = Pinecone.from_documents(data, embeddings, index_name='langchain-demo')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm, \n",
    "    chain_type=\"stuff\", \n",
    "    retriever=docsearch.as_retriever(), \n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QAGenerateChain\n",
    "Automates the creation of question answer sets for evaluatiom."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatGooglePalm(google_api_key=palm_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\USER\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\langchain\\chains\\llm.py:344: UserWarning: The apply_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# LLM-Generated examples\n",
    "example_gen_chain = QAGenerateChain.from_llm(llm=llm)\n",
    "\n",
    "# the warning below can be safely ignored\n",
    "examples = example_gen_chain.apply_and_parse(\n",
    "    [{\"doc\": t} for t in data[:5]]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'qa_pairs': {'query': \"What is John Doe's email address?\",\n",
       "   'answer': 'john.doe@email.com'}},\n",
       " {'qa_pairs': {'query': \"What is Jane Smith's email address?\",\n",
       "   'answer': 'jane.smith@email.com'}},\n",
       " {'qa_pairs': {'query': \"What is Bob Johnson's email address?\",\n",
       "   'answer': 'bob.johnson@email.com'}},\n",
       " {'qa_pairs': {'query': \"What is Alice Williams's email address?\",\n",
       "   'answer': 'alice.williams@email.com'}},\n",
       " {'qa_pairs': {'query': \"What is Charlie Brown's email address?\",\n",
       "   'answer': 'charlie.brown@email.com'}}]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new RetrievalQA chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'John Doe is a 28-year-old man who lives in New York City. His phone number is 555-1234.'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(examples[0]['qa_pairs']['answer'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Debugging\n",
    "This allows us to see the details of our chain execution. You set `debug=True`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"query\": \"john.doe@email.com\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain] Entering Chain run with input:\n",
      "\u001b[0m[inputs]\n",
      "\u001b[32;1m\u001b[1;3m[chain/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] Entering Chain run with input:\n",
      "\u001b[0m{\n",
      "  \"question\": \"john.doe@email.com\",\n",
      "  \"context\": \"Name: John Doe\\nAge: 28\\nEmail: john.doe@email.com\\nPhone: 555-1234\\nCity: New York\\n\\nName: Bob Johnson\\nAge: 42\\nEmail: bob.johnson@email.com\\nPhone: 555-9876\\nCity: Chicago\\n\\nName: Larry Green\\nAge: 40\\nEmail: larry.green@email.com\\nPhone: 555-1234\\nCity: San Diego\\n\\nName: Jane Smith\\nAge: 35\\nEmail: jane.smith@email.com\\nPhone: 555-5678\\nCity: Los Angeles\"\n",
      "}\n",
      "\u001b[32;1m\u001b[1;3m[llm/start]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:ChatGooglePalm] Entering LLM run with input:\n",
      "\u001b[0m{\n",
      "  \"prompts\": [\n",
      "    \"System: Use the following pieces of context to answer the user's question. \\nIf you don't know the answer, just say that you don't know, don't try to make up an answer.\\n----------------\\nName: John Doe\\nAge: 28\\nEmail: john.doe@email.com\\nPhone: 555-1234\\nCity: New York\\n\\nName: Bob Johnson\\nAge: 42\\nEmail: bob.johnson@email.com\\nPhone: 555-9876\\nCity: Chicago\\n\\nName: Larry Green\\nAge: 40\\nEmail: larry.green@email.com\\nPhone: 555-1234\\nCity: San Diego\\n\\nName: Jane Smith\\nAge: 35\\nEmail: jane.smith@email.com\\nPhone: 555-5678\\nCity: Los Angeles\\nHuman: john.doe@email.com\"\n",
      "  ]\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[llm/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain > 5:llm:ChatGooglePalm] [1.57s] Exiting LLM run with output:\n",
      "\u001b[0m{\n",
      "  \"generations\": [\n",
      "    [\n",
      "      {\n",
      "        \"text\": \"John Doe is a 28-year-old man who lives in New York City. His phone number is 555-1234.\",\n",
      "        \"generation_info\": null,\n",
      "        \"type\": \"ChatGeneration\",\n",
      "        \"message\": {\n",
      "          \"lc\": 1,\n",
      "          \"type\": \"constructor\",\n",
      "          \"id\": [\n",
      "            \"langchain\",\n",
      "            \"schema\",\n",
      "            \"messages\",\n",
      "            \"ChatMessage\"\n",
      "          ],\n",
      "          \"kwargs\": {\n",
      "            \"role\": \"1\",\n",
      "            \"content\": \"John Doe is a 28-year-old man who lives in New York City. His phone number is 555-1234.\"\n",
      "          }\n",
      "        }\n",
      "      }\n",
      "    ]\n",
      "  ],\n",
      "  \"llm_output\": null,\n",
      "  \"run\": null\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain > 4:chain:LLMChain] [1.57s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"text\": \"John Doe is a 28-year-old man who lives in New York City. His phone number is 555-1234.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA > 3:chain:StuffDocumentsChain] [1.57s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"output_text\": \"John Doe is a 28-year-old man who lives in New York City. His phone number is 555-1234.\"\n",
      "}\n",
      "\u001b[36;1m\u001b[1;3m[chain/end]\u001b[0m \u001b[1m[1:chain:RetrievalQA] [2.50s] Exiting Chain run with output:\n",
      "\u001b[0m{\n",
      "  \"result\": \"John Doe is a 28-year-old man who lives in New York City. His phone number is 555-1234.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Manual Evaluation\n",
    "import langchain\n",
    "langchain.debug = True\n",
    "\n",
    "qa.run(examples[0]['qa_pairs']['answer'])\n",
    "\n",
    "# Turn off the debug mode\n",
    "langchain.debug = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### QAEvalChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Postprocessing\n",
    "examples_ = [example['qa_pairs'] for example in examples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# LLM assisted evaluation\n",
    "predictions = qa.apply(examples_)\n",
    "\n",
    "eval_chain = QAEvalChain.from_llm(llm)\n",
    "\n",
    "graded_outputs = eval_chain.evaluate(examples_, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example 0:\n",
      "Question: What is John Doe's email address?\n",
      "Real Answer: john.doe@email.com\n",
      "Predicted Answer: John Doe's email address is john.doe@email.com.\n",
      "\n",
      "Example 1:\n",
      "Question: What is Jane Smith's email address?\n",
      "Real Answer: jane.smith@email.com\n",
      "Predicted Answer: Jane Smith's email address is jane.smith@email.com.\n",
      "\n",
      "Example 2:\n",
      "Question: What is Bob Johnson's email address?\n",
      "Real Answer: bob.johnson@email.com\n",
      "Predicted Answer: Bob Johnson's email address is bob.johnson@email.com.\n",
      "\n",
      "Example 3:\n",
      "Question: What is Alice Williams's email address?\n",
      "Real Answer: alice.williams@email.com\n",
      "Predicted Answer: Alice Williams's email address is alice.williams@email.com.\n",
      "\n",
      "Example 4:\n",
      "Question: What is Charlie Brown's email address?\n",
      "Real Answer: charlie.brown@email.com\n",
      "Predicted Answer: Charlie Brown's email address is charlie.brown@email.com. He is 25 years old and lives in Seattle.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'results': \"CORRECT\\n\\nThe student's answer is the same as the true answer.\"}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i, eg in enumerate(examples_):\n",
    "    print(f\"Example {i}:\")\n",
    "    print(\"Question: \" + predictions[i]['query'])\n",
    "    print(\"Real Answer: \" + predictions[i]['answer'])\n",
    "    print(\"Predicted Answer: \" + predictions[i]['result'])\n",
    "    # print(\"Predicted Grade: \" + graded_outputs[i]['text'])\n",
    "    print()\n",
    "\n",
    "graded_outputs[0]\n",
    "\n",
    "# LangChain evaluation platform\n",
    "# The LangChain evaluation platform, LangChain Plus, can be accessed here https://www.langchain.plus/.\n",
    "# Use the invite code `lang_learners_2023`\n",
    "# Reminder: Download your notebook to your local computer to save your work.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LangChain evaluation platform\n",
    "Allows evaluation in a similar fashion as we have done but with the aid of a nice UI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LangChain evaluation platform, `LangChain Plus`, can be accessed [here](https://www.langchain.plus/). Use the **invite code**: `lang_learners_2023`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
